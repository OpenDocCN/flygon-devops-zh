# 第十九章：评估

# 第一章

以下是本章提出的问题的一些示例答案：

1.  正确答案是**D**和**E**。

1.  Docker 容器对 IT 来说就像运输业的集装箱一样。它定义了如何打包货物的标准。在这种情况下，货物是开发人员编写的应用程序。供应商（在这种情况下是开发人员）负责将货物打包到集装箱中，并确保一切都符合预期。一旦货物被打包到集装箱中，它就可以被运输。由于它是一个标准的集装箱，承运人可以标准化他们的运输方式，如卡车、火车或船只。承运人并不真正关心集装箱里装的是什么。此外，从一种运输方式到另一种运输方式（例如，从火车到船）的装卸过程可以高度标准化。这极大地提高了运输的效率。类似于这一点的是 IT 中的运维工程师，他可以接收开发人员构建的软件容器，并以高度标准化的方式将其运输到生产系统并在那里运行，而不必担心容器里装的是什么。它会正常工作。

1.  容器改变游戏规则的一些原因如下：

+   容器是自包含的，因此如果它们在一个系统上运行，它们就可以在任何容器可以运行的地方运行。

+   容器可以在本地和云端以及混合环境中运行。这对于今天的典型企业非常重要，因为它允许顺利地从本地过渡到云端。

+   容器镜像是由最了解的人构建或打包的-开发人员。

+   容器镜像是不可变的，这对于良好的发布管理非常重要。

+   容器是基于封装（使用 Linux 命名空间和 cgroups）、秘密、内容信任和镜像漏洞扫描的安全软件供应链的推动者。

1.  任何给定的容器之所以可以在任何容器可以运行的地方运行，是因为：

+   +   容器是自包含的黑匣子。它们不仅封装了应用程序，还包括所有的依赖项，如库和框架、配置数据、证书等。

+   容器是基于广泛接受的标准，如 OCI。

1.  答案是**B**。容器对于现代应用程序以及将传统应用程序容器化都非常有用。对企业来说，后者的好处是巨大的。据报道，维护传统应用程序的成本节约了 50%或更多。这些传统应用程序发布新版本的时间可以减少高达 90%。这些数字是由真实的企业客户公开报道的。

1.  50%或更多。

1.  容器基于 Linux 命名空间（网络、进程、用户等）和 cgroups（控制组）。

# 第二章

以下是本章中提出的问题的一些示例答案：

1.  `docker-machine`可用于以下情景：

1.  在各种提供商上创建一个 VM，例如 VirtualBox、Hyper-V、AWS、MS Azure 或 Google Compute Engine，该 VM 将用作 Docker 主机。

1.  启动、停止或终止先前生成的 VM。

1.  通过此工具创建的本地或远程 Docker 主机 VM 进行 SSH。

1.  重新生成用于安全使用 Docker 主机 VM 的证书。

1.  A. 是的，使用 Docker for Windows，您可以开发和运行 Linux 容器。还可以使用此版本的 Docker for Desktop 开发和运行本机 Windows 容器，但本书中未讨论。使用 macOS 版本，您只能开发和运行 Linux 容器。

1.  脚本用于自动化流程，从而避免人为错误。构建、测试、共享和运行 Docker 容器是应该始终自动化以增加其可靠性和可重复性的任务。

1.  以下 Linux 发行版已获得 Docker 认证：RedHat Linux（RHEL）、CentOS、Oracle Linux、Ubuntu 等。

1.  以下 Windows 操作系统已获得 Docker 认证：Windows 10 专业版，Windows Server 2016 和 Windows Server 2019

# 第三章

以下是本章中提出的问题的一些示例答案：

1.  Docker 容器的可能状态如下：

+   `已创建`：已创建但尚未启动的容器

+   `重新启动`：正在重新启动的容器

+   `运行`：当前正在运行的容器

+   `暂停`：进程已暂停的容器

+   `退出`：运行并完成的容器

+   `死亡`：Docker 引擎尝试但未能停止的容器

1.  我们可以使用`docker container ls`（或旧的更短版本`docker ps`）来列出当前在 Docker 主机上运行的所有容器。请注意，这不会列出已停止的容器，对于这些容器，您需要额外的参数`--all`（或`-a`）。

1.  要列出所有容器的 ID，无论是运行还是停止，我们可以使用`docker container ls -a -q`，其中`-q`表示仅输出 ID。

# 第四章

以下是本章中提出的问题的一些示例答案：

1.  `Dockerfile`可能是这样的：

```
FROM ubuntu:19.04
RUN apt-get update && \
    apt-get install -y iputils-ping
CMD ping 127.0.0.1
```

请注意，在 Ubuntu 中，`ping`工具是`iputils-ping`包的一部分。构建名为`pinger`的镜像，例如，使用`docker image build -t my-pinger`。

2. `Dockerfile`可能是这样的：

```
FROM alpine:latest
RUN apk update && \
    apk add curl
```

使用`docker image build -t my-alpine:1.0`构建镜像。

3. 用于 Go 应用程序的`Dockerfile`可能是这样的：

```
FROM golang:alpine
WORKDIR /app
ADD . /app
RUN cd /app && go build -o goapp
ENTRYPOINT ./goapp
```

您可以在`~/fod/ch04/answer03`文件夹中找到完整的解决方案。

4. Docker 镜像具有以下特征：

1. 它是不可变的。

2. 它由一到多个层组成。

3. 它包含打包应用程序运行所需的文件和文件夹。

5. **C.** 首先，您需要登录 Docker Hub；然后，使用用户名正确标记您的镜像；最后，推送镜像。

# 第五章

以下是本章中提出的问题的一些示例答案：

玩弄卷的最简单方法是使用 Docker Toolbox，因为当直接使用 Docker for Desktop 时，卷存储在 Docker for Desktop 透明使用的（有点隐藏的）Linux VM 中。

因此，我们建议以下操作：

```
$ docker-machine create --driver virtualbox volume-test
$ docker-machine ssh volume-test
```

现在您在名为`volume-test`的 Linux VM 中，可以进行以下练习：

1.  创建一个命名卷，运行以下命令：

```
$ docker volume create my-products
```

1.  执行以下命令：

```
$ docker container run -it --rm \
 -v my-products:/data:ro \
 alpine /bin/sh
```

1.  要获取卷在主机上的路径，请使用此命令：

```
$ docker volume inspect my-products | grep Mountpoint
```

（如果您使用`docker-machine`和 VirtualBox）应该导致这样：

```
"Mountpoint": "/mnt/sda1/var/lib/docker/volumes/myproducts/_data"
```

现在执行以下命令：

```
$ sudo su
$ cd /mnt/sda1/var/lib/docker/volumes/my-products/_data
$ echo "Hello world" > sample.txt
$ exit
```

1.  执行以下命令：

```
$ docker run -it --rm -v my-products:/data:ro alpine /bin/sh
/ # cd /data
/data # cat sample.txt
```

在另一个终端中，执行此命令：

```
$ docker run -it --rm -v my-products:/app-data alpine /bin/sh
/ # cd /app-data
/app-data # echo "Hello other container" > hello.txt
/app-data # exit
```

1.  执行这样的命令：

```
$ docker container run -it --rm \
 -v $HOME/my-project:/app/data \
 alpine /bin/sh
```

1.  退出两个容器，然后回到主机上，执行此命令：

```
$ docker volume prune
```

1.  答案是 B。每个容器都是一个沙盒，因此具有自己的环境。

1.  收集所有环境变量及其相应的值到一个配置文件中，然后在`docker run`命令中使用`--env-file`命令行参数将其提供给容器，就像这样：

```
$ docker container run --rm -it \
 --env-file ./development.config \
 alpine sh -c "export"
```

# 第六章

以下是本章中提出的问题的一些示例答案：

1.  可能的答案：a) 在容器中挂载源代码；b) 使用工具，在检测到代码更改时自动重新启动容器内运行的应用程序；c) 为远程调试配置容器。

1.  您可以在容器中将包含源代码的文件夹挂载到主机上。

1.  如果你无法轻松地通过单元测试或集成测试覆盖某些场景，如果观察到的应用程序行为无法在主机上重现。另一种情况是由于缺乏必要的语言或框架，无法直接在主机上运行应用程序的情况。

1.  一旦应用程序在生产环境中运行，作为开发人员，我们无法轻易访问它。如果应用程序出现意外行为甚至崩溃，日志通常是我们唯一的信息来源，帮助我们重现情况并找出错误的根本原因。

# 第七章

以下是本章提出的问题的一些示例答案：

1.  优缺点：

+   优点：我们不需要在主机上安装任务所需的特定 shell、工具或语言。

+   优点：我们可以在任何 Docker 主机上运行，从树莓派到大型计算机；唯一的要求是主机能够运行容器。

+   优点：成功运行后，当容器被移除时，工具会从主机上完全清除痕迹。

+   缺点：我们需要在主机上安装 Docker。

+   缺点：用户需要对 Docker 容器有基本的了解。

+   缺点：使用该工具比直接在本机使用要间接一些。

1.  在容器中运行测试具有以下优点：

+   它们在开发者机器上和测试或 CI 系统上同样运行良好。

+   更容易以相同的初始条件开始每次测试运行。

+   所有使用代码的开发人员使用相同的设置，例如库和框架的版本。

1.  在这里，我们期望看到一个图表，显示开发人员编写代码并将其检入，例如 GitHub。然后我们希望在图中看到一个自动化服务器，比如 Jenkins 或 TeamCity，它要么定期轮询 GitHub 进行更改，要么 GitHub 触发自动化服务器（通过 HTTP 回调）创建新的构建。图表还应显示自动化服务器然后运行所有测试以针对构建的工件，如果所有测试都成功，则部署应用程序或服务到集成系统，在那里再次进行测试，例如进行一些 smoke 测试。再次，如果这些测试成功，自动化服务器应该要么要求人类批准部署到生产环境（这相当于持续交付），要么自动部署到生产环境（持续部署）。

# 第八章

以下是本章提出的问题的一些示例答案：

1.  您可能正在使用资源或功能有限的工作站工作，或者您的工作站可能被公司锁定，以便您不被允许安装任何未经官方批准的软件。有时，您可能需要使用公司尚未批准的语言或框架进行概念验证或实验（但如果概念验证成功，可能将来会被批准）。

1.  将 Docker 套接字绑定到容器是当容器化应用程序需要自动执行一些与容器相关的任务时的推荐方法。这可以是一个应用程序，比如您正在使用它来构建、测试和部署 Docker 镜像的自动化服务器，比如 Jenkins。

1.  大多数商业应用程序不需要根级授权来完成其工作。从安全的角度来看，强烈建议以尽可能少的访问权限来运行这些应用程序。任何不必要的提升权限都可能被黑客利用进行恶意攻击。通过以非根用户身份运行应用程序，可以使潜在黑客更难以 compromise 您的系统。

1.  卷包含数据，数据的寿命往往需要远远超出容器或应用程序的生命周期。数据通常是至关重要的，并且需要安全地存储数天、数月，甚至数年。当您删除一个卷时，您将不可逆地删除与其关联的数据。因此，在删除卷时，请确保知道自己在做什么。

# 第九章

以下是本章提出的问题的一些示例答案：

1.  在分布式应用架构中，软件和基础设施的每个部分在生产环境中都需要冗余，因为应用的持续运行时间至关重要。高度分布式的应用程序由许多部分组成，其中一个部分失败或行为不当的可能性随着部分数量的增加而增加。可以保证，足够长的时间后，每个部分最终都会失败。为了避免应用中断，我们需要在每个部分都有冗余，无论是服务器、网络交换机还是在容器中运行的集群节点上的服务。

1.  在高度分布式、可扩展和容错的系统中，应用程序的各个服务可能会因为扩展需求或组件故障而移动。因此，我们不能将不同的服务硬编码在一起。需要访问服务 B 的服务 A 不应该知道诸如服务 B 的 IP 地址之类的细节，而应该依赖于提供此信息的外部提供者。DNS 就是这样一个位置信息的提供者。服务 A 只需告诉 DNS 它想要与服务 B 通信，DNS 服务将找出详细信息。

1.  断路器是避免级联故障的一种手段，如果分布式应用程序中的一个组件失败或行为不当。类似于电气布线中的断路器，软件驱动的断路器会切断客户端与失败服务之间的通信。如果调用了失败的服务，断路器将直接向客户端组件报告错误。这为系统提供了从故障中恢复或修复的机会。

1.  单体应用程序比多服务应用程序更容易管理，因为它由单个部署包组成。另一方面，单体应用程序很难扩展以满足增加的需求。在分布式应用程序中，每个服务都可以单独扩展，并且每个服务都可以在优化的基础设施上运行，而单体应用程序需要在适用于其实现的所有或大多数功能的基础设施上运行。维护和更新单体应用程序比多服务应用程序要困难得多，因为每个服务都可以独立更新和部署。单体通常是一堆复杂且紧密耦合的代码。小的修改可能会产生意想不到的副作用。另一方面，（微）服务是自包含的、简单的组件，其行为类似于黑匣子。依赖服务对服务的内部工作一无所知，因此不依赖于它。

1.  蓝绿部署是一种软件部署形式，允许无零停机部署应用程序或应用程序服务的新版本。例如，如果服务 A 需要使用新版本进行更新，那么我们称当前运行的版本为蓝色。服务的新版本部署到生产环境，但尚未与应用程序的其余部分连接。这个新版本被称为绿色。一旦部署成功并且冒烟测试表明它已经准备就绪，将负责将流量引导到蓝色的路由器重新配置为切换到绿色。观察绿色的行为一段时间，如果一切正常，蓝色将被废弃。另一方面，如果绿色造成困难，路由器可以简单地切换回蓝色，然后修复绿色并稍后重新部署。

# 第十章

以下是本章中提出的一些问题的样本答案：

1.  三个核心元素是**沙盒**、**端点**和**网络**。

1.  执行此命令：

```
$ docker network create --driver bridge frontend
```

1.  运行此命令：

```

$ docker container run -d --name n1 \
 --network frontend -p 8080:80 nginx:alpine
$ docker container run -d --name n2 \
 --network frontend -p 8081:80 nginx:alpine
```

测试两个 NGINX 实例是否正常运行：

```
$ curl -4 localhost:8080
$ curl -4 localhost:8081
```

在这两种情况下，您应该看到 NGINX 的欢迎页面。

1.  要获取所有已附加容器的 IP，请运行此命令：

```
$ docker network inspect frontend | grep IPv4Address
```

您应该看到类似以下内容：

```
"IPv4Address": "172.18.0.2/16",
"IPv4Address": "172.18.0.3/16",
```

要获取网络使用的子网，请使用以下命令（例如）：

```
$ docker network inspect frontend | grep subnet
```

您应该收到类似以下内容的信息（从上一个示例中获得）：

```
"Subnet": "172.18.0.0/16",
```

1.  “主机”网络允许我们在主机的网络命名空间中运行容器。

1.  仅在调试目的或构建系统级工具时使用此网络。永远不要在运行生产环境的应用程序容器中使用`host`网络！

1.  `none`网络基本上表示容器未连接到任何网络。它应该用于不需要与其他容器通信并且不需要从外部访问的容器。

1.  例如，`none`网络可以用于在容器中运行的批处理过程，该过程只需要访问本地资源，例如可以通过主机挂载卷访问的文件。

1.  Traefik 可用于提供第 7 层或应用程序级别的路由。如果要从单体中分离功能并具有明确定义的 API，则这将非常有用。在这种情况下，您需要重新路由某些 HTTP 调用到新的容器/服务。这只是可能的使用场景之一，但也是最重要的一个。另一个可能是将 Traefik 用作负载均衡器。

# 第十一章

以下是本章提出的问题的一些示例答案：

1.  以下代码可用于以分离或守护程序模式运行应用程序：

```
$ docker-compose up -d
```

1.  执行以下命令以显示运行服务的详细信息：

```
$ docker-compose ps
```

这应该导致以下输出：

```
Name               Command               State  Ports
-------------------------------------------------------------------
mycontent_nginx_1  nginx -g daemon off;  Up     0.0.0.0:3000->80/tcp
```

1.  以下命令可用于扩展 Web 服务：

```
$ docker-compose up --scale web=3
```

# 第十二章

以下是本章提出的问题的一些示例答案：

1.  作为高度分布式的关键任务，高可用性应用程序实现为相互连接的应用程序服务系统，这些系统过于复杂，无法手动监视、操作和管理。容器编排器在这方面有所帮助。它们自动化了大部分典型任务，例如协调所需状态，或收集和聚合系统的关键指标。人类无法快速反应，以使这样的应用程序具有弹性或自我修复能力。软件支持是必要的，这就是所提到的容器编排器的形式。

1.  容器编排器使我们摆脱了以下繁琐和繁重的任务：

+   扩展服务的规模

+   负载均衡请求

+   将请求路由到所需的目标

+   监视服务实例的健康状况

+   保护分布式应用程序

1.  在这个领域的赢家是 Kubernetes，它是由 CNCF 开源并拥有。它最初是由 Google 开发的。我们还有 Docker Swarm，它是专有的，并由 Docker 开发。AWS 提供了一个名为 ECS 的容器服务，它也是专有的，并且与 AWS 生态系统紧密集成。最后，微软提供了 AKS，它与 AWS ECS 具有相同的优缺点。

# 第十三章

以下是本章中提出的一些问题的样本答案：

1.  正确答案如下：

```
$ docker swarm init [--advertise-addr <IP address>]
```

`--advertise-addr`是可选的，只有在主机有多个 IP 地址时才需要。

1.  在要移除的工作节点上执行以下命令：

```
 $ docker swarm leave
```

在其中一个主节点上执行命令`$ docker node rm -f<node ID>`，其中`<node ID>`是要移除的工作节点的 ID。

1.  正确答案如下：

```
$ docker network create \
 --driver overlay \
 --attachable \
 front-tier
```

1.  正确答案如下：

```
$ docker service create --name web \
 --network front-tier \
 --replicas 5 \
 -p 3000:80 \
 nginx:alpine
```

1.  正确答案如下：

```
$ docker service update --replicas 3 web
```

# 第十四章

以下是本章中提出的一些问题的样本答案：

1.  零停机部署意味着在分布式应用程序中，服务的新版本可以更新到新版本，而无需停止应用程序的运行。通常情况下，使用 Docker SwarmKit 或 Kubernetes（如我们将看到的那样），这是以滚动方式完成的。一个服务由多个实例组成，这些实例会分批更新，以确保大多数实例始终处于运行状态。

1.  默认情况下，Docker SwarmKit 使用滚动更新策略来实现零停机部署。

1.  容器是部署的自包含单元。如果部署的服务的新版本不如预期地工作，我们（或系统）只需要回滚到以前的版本。服务的以前版本也是以自包含容器的形式部署的。在概念上，向前（更新）或向后（回滚）滚动没有区别。一个容器的版本被另一个版本替换。主机本身不会受到这些变化的任何影响。

1.  Docker secrets 在静止状态下是加密的。它们只会传输给使用这些秘密的服务和容器。秘密之间的通信是加密的，因为 swarm 节点之间的通信使用相互 TLS。秘密从未在工作节点上物理存储。

1.  实现此目的的命令如下：

```
$ docker service update --image acme/inventory:2.1 \
 --update-parallelism 2 \
 --update-delay 60s \
 inventory
```

6.首先，我们需要从服务中删除旧的秘密，然后将新版本添加到其中（直接更新秘密是不可能的）：

```
$ docker service update \
 --secret-rm MYSQL_PASSWORD \
 inventory
$ docker service update \
 --secret-add source=MYSQL_PASSWORD_V2, target=MYSQL_PASSWORD \
 inventory
```

# 第十五章

以下是本章中提出的问题的一些示例答案：

1.  Kubernetes 主节点负责管理集群。所有创建对象、重新调度 pod、管理 ReplicaSets 等请求都在主节点上进行。主节点不会在生产或类似生产的集群中运行应用程序工作负载。

1.  在每个工作节点上，我们都有 kubelet、代理和容器运行时。

1.  答案是 A。**是**。你不能在 Kubernetes 集群上运行独立的容器。Pods 是这样一个集群中部署的原子单位。

1.  在一个 pod 内运行的所有容器共享相同的 Linux 内核网络命名空间。因此，所有在这些容器内运行的进程可以通过`localhost`相互通信，类似于直接在主机上运行的进程或应用程序可以通过`localhost`相互通信的方式。

1.  `pause`容器的唯一作用是为在其中运行的容器保留 pod 的命名空间。

1.  这是一个坏主意，因为一个 pod 的所有容器都是共同定位的，这意味着它们运行在同一个集群节点上。此外，如果多个容器在同一个 pod 中运行，它们只能一起扩展或缩减。然而，应用程序的不同组件（即`web`、`inventory`和`db`）通常在可伸缩性或资源消耗方面有非常不同的要求。`web`组件可能需要根据流量进行扩展或缩减，而`db`组件则对存储有特殊要求，而其他组件则没有。如果我们将每个组件都运行在自己的 pod 中，我们在这方面会更加灵活。

1.  我们需要一种机制来在集群中运行多个 pod 实例，并确保实际运行的 pod 数量始终与期望的数量相对应，即使个别 pod 由于网络分区或集群节点故障而崩溃或消失。 ReplicaSet 是为任何应用程序服务提供可伸缩性和自愈能力的机制。

1.  每当我们想要在 Kubernetes 集群中更新应用程序服务而不会导致服务中断时，我们都需要部署对象。部署对象为 ReplicaSets 添加了滚动更新和回滚功能。

1.  Kubernetes 服务对象用于使应用程序服务参与服务发现。它们为一组 pod 提供了一个稳定的端点（通常由 ReplicaSet 或部署管理）。Kube 服务是定义了一组逻辑 pod 和访问它们的策略的抽象。有四种类型的 Kube 服务：

+   **ClusterIP**：在集群内部的 IP 地址上公开服务；这是一个虚拟 IP（VIP）。

+   **NodePort**：在每个集群节点上发布 30,000-32,767 范围内的端口。

+   **LoadBalancer**：这种类型使用云提供商的负载均衡器（如 AWS 上的 ELB）来外部公开应用程序服务。

+   **ExternalName**：当您需要为集群的外部服务（如数据库）定义代理时使用。

# 第十六章

以下是本章中提出的问题的一些示例答案：

1.  假设我们在两个应用程序服务的注册表中有一个 Docker 镜像，web API 和 Mongo DB，然后我们需要做以下操作：

+   使用 StatefulSet 为 Mongo DB 定义一个部署；让我们称之为`db-deployment`。StatefulSet 应该有一个副本（复制 Mongo DB 需要更多的工作，超出了本书的范围）。

+   为`db-deployment`定义一个名为`db`的 Kubernetes 服务，类型为`ClusterIP`。

+   为 web API 定义一个部署；让我们称之为`web-deployment`。将这个服务扩展到三个实例。

+   为`web-deployment`定义一个名为`api`的 Kubernetes 服务，类型为`NodePort`。

+   如果我们使用 secrets，那么使用 kubectl 直接在集群中定义这些 secrets。

+   使用 kubectl 部署应用程序。

1.  为了实现应用程序的第 7 层路由，我们理想情况下使用 IngressController。IngressController 是一个反向代理，比如 Nginx，它有一个 sidecar 监听 Kubernetes Server API 的相关变化，并更新反向代理的配置，如果检测到变化，则重新启动。然后，我们需要在集群中定义 Ingress 资源，定义路由，例如基于上下文的路由，比如`https://example.com/pets`到`<服务名称>/<端口>`，或者一对，比如`api/32001`。一旦 Kubernetes 创建或更改了这个 Ingress 对象，IngressController 的 sidecar 就会接收并更新代理的路由配置。

1.  假设这是一个集群内部的库存服务，那么我们需要做以下操作：

+   在部署版本 1.0 时，我们定义了一个名为`inventory-deployment-blue`的部署，并使用`color: blue`的标签标记 pod。

+   我们部署了 Kubernetes 服务的`ClusterIP`类型，称为 inventory，前面的部署中包含选择器`color: blue`。

+   当我们准备部署支付服务的新版本时，我们为服务的 2.0 版本定义一个部署，并称其为`inventory-deployment-green`。我们向 pod 添加了`color: green`的标签。

+   现在我们可以对“green”服务进行冒烟测试，当一切正常时，我们可以更新 inventory 服务，以便选择器包含`color: green`。

1.  一些机密的信息形式应通过 Kubernetes secrets 提供给服务，包括密码、证书、API 密钥 ID、API 密钥密钥和令牌。

1.  秘密值的来源可以是文件或 base64 编码的值。

# 第十七章

以下是本章中提出的问题的一些示例答案：

1.  出于性能和安全原因，我们不能在生产系统上进行任何实时调试。这包括交互式或远程调试。然而，应用服务可能会因代码缺陷或其他基础设施相关问题（如网络故障或不可用的外部服务）而表现出意外行为。为了快速找出服务的异常行为或失败的原因，我们需要尽可能多的日志信息。这些信息应该给我们一个线索，并引导我们找到错误的根本原因。当我们对服务进行仪器化时，我们确实做到了这一点——以日志条目和发布的指标的形式产生尽可能多的信息。

1.  Prometheus 是一个用于收集其他基础设施服务和最重要的应用服务提供的功能或非功能指标的服务。由于 Prometheus 本身定期从所有配置的服务中拉取这些指标，因此服务本身不必担心发送数据。Prometheus 还定义了生产者呈现指标的格式。

1.  要对基于 Node.js 的应用服务进行仪器化，我们需要执行以下四个步骤：

1.  向项目添加 Prometheus 适配器。Prometheus 的维护者推荐使用名为`siimon/prom-client`的库。

1.  在应用程序启动期间配置 Prometheus 客户端。这包括定义一个指标注册表。

1.  公开一个 HTTP GET 端点/度量标准，返回度量标准注册表中定义的度量集合。

1.  最后，我们定义`counter`、`gauge`或`histogram`类型的自定义度量标准，并在我们的代码中使用它们；例如，每次调用特定端点时，我们增加`counter`类型的度量标准。

1.  通常在生产环境中，Kubernetes 集群节点只包含最小的操作系统，以尽可能限制其攻击面，并且不浪费宝贵的资源。因此，我们不能假设通常用于排除应用程序或进程的工具在相应的主机上可用。排除故障的一种强大且推荐的方法是作为临时 Pod 的一部分运行特殊工具或排除故障容器。然后，该容器可以用作我们可以调查受困扰的服务的网络和其他问题的堡垒。许多 Docker 现场工程师在客户现场成功使用的容器是`netshoot`。

# 第十八章

以下是本章中提出的问题的一些示例答案：

1.  要在 AWS 中安装 UCP，我们执行以下操作：

+   创建具有子网和 SG 的 VPC。

+   然后，提供一组 Linux VM 的集群，可能作为 ASG 的一部分。支持许多 Linux 发行版，如 CentOS、RHEL 和 Ubuntu。

+   然后，在每个 VM 上安装 Docker。

+   最后，选择一个 VM 来安装 UCP，使用`docker/ucp`镜像。

+   安装 UCP 后，将其他 VM 加入集群，作为工作节点或管理节点。

1.  以下是考虑托管 Kubernetes 的一些原因：

+   您不希望或没有资源来安装和管理 Kubernetes 集群。

+   您希望专注于为您的业务带来价值的内容，这在大多数情况下是应该在 Kubernetes 上运行的应用程序，而不是 Kubernetes 本身。

+   您更喜欢按需付费的成本模型。

+   您的 Kubernetes 集群节点会自动打补丁和更新。

+   升级 Kubernetes 版本而无需停机时间非常简单和直接。

1.  将容器镜像托管在云提供商的容器注册表（例如 Microsoft Azure 上的 ACR）的两个主要原因是：

+   镜像地理位置靠近您的 Kubernetes 集群，因此延迟和传输网络成本最小。

+   生产或类似生产的集群理想情况下应该与互联网隔离，因此 Kubernetes 集群节点无法直接访问 Docker Hub。
