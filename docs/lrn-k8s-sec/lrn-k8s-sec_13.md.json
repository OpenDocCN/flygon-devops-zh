["```\napiVersion: audit.k8s.io/v1 # This is required.\nkind: Policy\n# Skip generating audit events for all requests in RequestReceived stage. This can be either set at the policy level or rule level.\nomitStages:\n  - \"RequestReceived\"\nrules:\n  # Log pod changes at RequestResponse level\n  - level: RequestResponse\n    verbs: [\"create\", \"update\"]\n    namespace: [\"ns1\", \"ns2\", \"ns3\"]\n    resources:\n    - group: \"\"\n# Only check access to resource \"pods\", not the sub-resource of pods which is consistent with the RBAC policy.\n      resources: [\"pods\"]\n# Log \"pods/log\", \"pods/status\" at Metadata level\n  - level: Metadata\n    resources:\n    - group: \"\"\n      resources: [\"pods/log\", \"pods/status\"]\n# Don't log authenticated requests to certain non-resource URL paths.\n  - level: None\n    userGroups: [\"system:authenticated\"]\n    nonResourceURLs: [\"/api*\", \"/version\"]\n# Log configmap and secret changes in all other namespaces at the Metadata level.\n  - level: Metadata\n    resources:\n    - group: \"\" # core API group\n      resources: [\"secrets\", \"configmaps\"]\n```", "```\n{\n  \"kind\": \"Event\",\n  \"apiVersion\": \"audit.k8s.io/v1\",\n  \"level\": \"Metadata\",\n  \"auditID\": \"05698e93-6ad7-4f4e-8ae9-046694bee469\",\n  \"stage\": \"ResponseComplete\",\n  \"requestURI\": \"/api/v1/namespaces/ns1/pods\",\n  \"verb\": \"create\",\n  \"user\": {\n    \"username\": \"admin\",\n    \"uid\": \"admin\",\n    \"groups\": [\n      \"system:masters\",\n      \"system:authenticated\"\n    ]\n  },\n  \"sourceIPs\": [\n    \"98.207.36.92\"\n  ],\n  \"userAgent\": \"kubectl/v1.17.4 (darwin/amd64) kubernetes/8d8aa39\",\n  \"objectRef\": {\n    \"resource\": \"pods\",\n    \"namespace\": \"ns1\",\n    \"name\": \"pod-1\",\n    \"apiVersion\": \"v1\"\n  },\n  \"responseStatus\": {\n    \"metadata\": {},\n    \"code\": 201\n  },\n  \"requestReceivedTimestamp\": \"2020-04-09T07:10:52.471720Z\",\n  \"stageTimestamp\": \"2020-04-09T07:10:52.485551Z\",\n  \"annotations\": {\n    \"authorization.k8s.io/decision\": \"allow\",\n    \"authorization.k8s.io/reason\": \"\"\n  }\n}\n```", "```\n  \"requestObject\": {\n    \"kind\": \"Pod\",\n    \"apiVersion\": \"v1\",\n    \"metadata\": {\n      \"name\": \"pod-2\",\n      \"namespace\": \"ns2\",\n      \"creationTimestamp\": null,\n      ...\n    },\n    \"spec\": {\n      \"containers\": [\n        {\n          \"name\": \"echo\",\n          \"image\": \"busybox\",\n          \"command\": [\n            \"sh\",\n            \"-c\",\n            \"echo 'this is echo' && sleep 1h\"\n          ],\n          ...\n          \"imagePullPolicy\": \"Always\"\n        }\n      ],\n      ...\n      \"securityContext\": {},\n    },\n```", "```\n{\n  \"responseObject\": {\n      ...\n      \"selfLink\": \"/api/v1/namespaces/ns3/pods/pod-3\",\n      \"uid\": \"3fd18de1-7a31-11ea-9e8d-0a39f00d8287\",\n      \"resourceVersion\": \"217243\",\n      \"creationTimestamp\": \"2020-04-09T07:10:53Z\",\n      \"tolerations\": [\n        {\n          \"key\": \"node.kubernetes.io/not-ready\",\n          \"operator\": \"Exists\",\n          \"effect\": \"NoExecute\",\n          \"tolerationSeconds\": 300\n        },\n        {\n          \"key\": \"node.kubernetes.io/unreachable\",\n          \"operator\": \"Exists\",\n          \"effect\": \"NoExecute\",\n          \"tolerationSeconds\": 300\n        }\n      ],\n      ...\n    },\n }\n```", "```\napiVersion: v1\nkind: Config\nclusters:\n- name: falco\n  cluster:\n    server: http://$FALCO_SERVICE_CLUSTERIP:8765/k8s_audit\ncontexts:\n- context:\n    cluster: falco\n    user: \"\"\n  name: default-context\ncurrent-context: default-context\npreferences: {}\nusers: []\n```", "```\n$ kubectl get pods -n kube-system\n...\netcd-manager-events-ip-172-20-109-109.ec2.internal       1/1     Running   0          4h15m\netcd-manager-events-ip-172-20-43-65.ec2.internal         1/1     Running   0          4h16m\netcd-manager-events-ip-172-20-67-151.ec2.internal        1/1     Running   0          4h16m\netcd-manager-main-ip-172-20-109-109.ec2.internal         1/1     Running   0          4h15m\netcd-manager-main-ip-172-20-43-65.ec2.internal           1/1     Running   0          4h15m\netcd-manager-main-ip-172-20-67-151.ec2.internal          1/1     Running   0          4h16m\nkube-apiserver-ip-172-20-109-109.ec2.internal            1/1     Running   3          4h15m\nkube-apiserver-ip-172-20-43-65.ec2.internal              1/1     Running   4          4h16m\nkube-apiserver-ip-172-20-67-151.ec2.internal             1/1     Running   4          4h15m\nkube-controller-manager-ip-172-20-109-109.ec2.internal   1/1     Running   0          4h15m\nkube-controller-manager-ip-172-20-43-65.ec2.internal     1/1     Running   0          4h16m\nkube-controller-manager-ip-172-20-67-151.ec2.internal    1/1     Running   0          4h15m\nkube-scheduler-ip-172-20-109-109.ec2.internal            1/1     Running   0          4h15m\nkube-scheduler-ip-172-20-43-65.ec2.internal              1/1     Running   0          4h15m\nkube-scheduler-ip-172-20-67-151.ec2.internal             1/1     Running   0          4h16m\n```", "```\nexport NODE_SIZE=${NODE_SIZE:-t2.large}\nexport MASTER_SIZE=${MASTER_SIZE:-t2.medium}\nexport ZONES=${ZONES:-\"us-east-1a,us-east-1b,us-east-1c\"}\nexport KOPS_STATE_STORE=\"s3://my-k8s-state-store2/\"\nkops create cluster k8s-clusters.k8s-demo-zone.com \\\n  --cloud aws \\\n  --node-count 3 \\\n  --zones $ZONES \\\n  --node-size $NODE_SIZE \\\n  --master-size $MASTER_SIZE \\\n  --master-zones $ZONES \\\n  --networking calico \\\n  --kubernetes-version 1.14.3 \\\n  --yes \\\n```", "```\n$ kops validate cluster\n...\nINSTANCE GROUPS\nNAME\t\t\tROLE\tMACHINETYPE\tMIN\tMAX\tSUBNETS\nmaster-us-east-1a\tMaster\tt2.medium\t1\t1\tus-east-1a\nmaster-us-east-1b\tMaster\tt2.medium\t1\t1\tus-east-1b\nmaster-us-east-1c\tMaster\tt2.medium\t1\t1\tus-east-1c\nnodes\t\t\tNode\tt2.large\t3\t3\tus-east-1a,us-east-1b,us-east-1c\n```", "```\nhelm install vault --set='server.dev.enabled=true' https://github.com/hashicorp/vault-helm/archive/v0.4.0.tar.gz\n```", "```\n$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\nvault-0                                 1/1     Running   0          80s\nvault-agent-injector-7fd6b9588b-fgsnj   1/1     Running   0          80s\n```", "```\nvault kv put secret/postgres username=alice password=pass\n```", "```\ncat <<EOF > /home/vault/app-policy.hcl\npath \"secret*\" {\n  capabilities = [\"read\"]\n}\nEOF\nvault policy write app /home/vault/app-policy.hcl\n```", "```\nvault auth enable kubernetes\nvault write auth/kubernetes/config \\\n   token_reviewer_jwt=\"$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)\" \\\n   kubernetes_host=https://${KUBERNETES_PORT_443_TCP_ADDR}:443 \\\n   kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\nvault write auth/kubernetes/role/myapp \\\n   bound_service_account_names=app \\\n   bound_service_account_namespaces=demo \\\n   policies=app \\\n   ttl=24h\n```", "```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: vault-agent-demo\nspec:\n  selector:\n    matchLabels:\n      app: vault-agent-demo\n  replicas: 1\n  template:\n    metadata:\n      annotations:\n      labels:\n        app: vault-agent-demo\n    spec:\n      serviceAccountName: app\n      containers:\n      - name: app\n        image: jweissig/app:0.0.1\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app\n  labels:\n    app: vault-agent-demo\n```", "```\n$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\napp-668b8bcdb9-js9mm                    1/1     Running   0          3m23s\n```", "```\n$ cat patch-template-annotation.yaml\nspec:\n  template:\n    metadata:\n      annotations:\n        vault.hashicorp.com/agent-inject: \"true\"\n        vault.hashicorp.com/agent-inject-status: \"update\"\n        vault.hashicorp.com/agent-inject-secret-postgres: \"secret/postgres\"\n        vault.hashicorp.com/agent-inject-template-postgres: |\n          {{- with secret \"secret/postgres\" -}}\n          postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n          {{- end }}\n        vault.hashicorp.com/role: \"myapp\"\n```", "```\n$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\napp-68d47bb844-2hlrb                    2/2     Running   0          13s\n$ kubectl -n demo exec -it app-68d47bb844-2hlrb -c app -- cat /vault/secrets/postgres\npostgresql://alice:pass@postgres:5432/wizard\n```", "```\n  containers:\n  - image: jweissig/app:0.0.1\n    ...\n    volumeMounts:\n    - mountPath: /vault/secrets\n      name: vault-secrets\n  - args:\n    - echo ${VAULT_CONFIG?} | base64 -d > /tmp/config.json && vault agent -config=/tmp/config.json\n    command:\n    - /bin/sh\n    - -ec\n    image: vault:1.3.2\n    name: vault-agent\n    volumeMounts:\n    - mountPath: /vault/secrets\n      name: vault-secrets\n initContainers:\n  - args:\n    - echo ${VAULT_CONFIG?} | base64 -d > /tmp/config.json && vault agent -config=/tmp/config.json\n    command:\n    - /bin/sh\n    - -ec\n    image: vault:1.3.2\n    name: vault-agent-init\n    volumeMounts:\n    - mountPath: /vault/secrets\n      name: vault-secrets\n  volumes:\n   - emptyDir:\n      medium: Memory\n    name: vault-secrets\n```", "```\napiVersion: admissionregistration.k8s.io/v1beta1\nkind: MutatingWebhookConfiguration\nmetadata:\n  ...\n  name: vault-agent-injector-cfg\nwebhooks:\n- admissionReviewVersions:\n  - v1beta1\n  clientConfig:\n    caBundle: <CA_BUNDLE>\n    service:\n      name: vault-agent-injector-svc\n      namespace: demo\n      path: /mutate\n  failurePolicy: Ignore\n  name: vault.hashicorp.com\n  namespaceSelector: {}\n  rules:\n  - apiGroups:\n    - \"\"\n    apiVersions:\n    - v1\n    operations:\n    - CREATE\n    - UPDATE\n    resources:\n    - pods\n    scope: '*'\n```", "```\nvault kv put secret/postgres username=alice password=changeme\n```", "```\n$ kubectl -n demo exec -it app-68d47bb844-2hlrb -c app -- cat /vault/secrets/postgres\npostgresql://alice:changeme@postgres:5432/wizard\n```", "```\nhelm install --name falco stable/falco\n```", "```\n$ kubectl get pods\nNAME          READY   STATUS    RESTARTS   AGE\nfalco-9h8tg   1/1     Running   10         62m\nfalco-cnt47   1/1     Running   5          3m45s\nfalco-mz6jg   1/1     Running   0          6s\nfalco-t4cpw   1/1     Running   0          10s\n```", "```\n    - rule: Anomalous read in nginx pod\n      desc: Detect any anomalous file read activities in Nginx pod.\n      condition: (open_read and container and container.image.repository=\"kaizheh/insecure-nginx\" and fd.directory != \"/usr/share/nginx/html\")\n      output: Anomalous file read activity in Nginx pod (user=%user.name process=%proc.name file=%fd.name container_id=%container.id image=%container.image.repository)\n      priority: WARNING\n```", "```\n# curl insecure-nginx.insecure-nginx.svc.cluster.local/files../etc/passwd\nroot:x:0:0:root:/root:/bin/bash\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\nsync:x:4:65534:sync:/bin:/bin/sync\ngames:x:5:60:games:/usr/games:/usr/sbin/nologin\nman:x:6:12:man:/var/cache/man:/usr/sbin/nologin\nlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin\nmail:x:8:8:mail:/var/mail:/usr/sbin/nologin\nnews:x:9:9:news:/var/spool/news:/usr/sbin/nologin\nuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin\nproxy:x:13:13:proxy:/bin:/usr/sbin/nologin\nwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologin\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\nirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\n_apt:x:100:65534::/nonexistent:/bin/false\n```", "```\n08:22:19.484698397: Warning Anomalous file read activity in Nginx pod (user=<NA> process=nginx file=/etc/passwd container_id=439e2e739868 image=kaizheh/insecure-nginx) k8s.ns=insecure-nginx k8s.pod=insecure-nginx-7c99fdf44b-gffp4 container=439e2e739868 k8s.ns=insecure-nginx k8s.pod=insecure-nginx-7c99fdf44b-gffp4 container=439e2e739868\n```", "```\n- list: trusted_images\n  items: [calico/node, kopeio/etcd-manager, k8s.gcr.io/kube-apiserver, k8s.gcr.io/kube-controller-manager, k8s.gcr.io/kube-proxy, k8s.gcr.io/kube-scheduler]\n- rule: Untrusted Image Deployed in kube-system Namespace\n  desc: >\n    Detect an untrusted image deployed in kube-system namespace\n  condition: >\n    kevt and pod\n    and kcreate\n    and ka.target.namespace=kube-system\n    and not ka.req.pod.containers.image.repository in (trusted_images)\n  output: Untrusted image deployed in kube-system namespace (user=%ka.user.name image=%ka.req.pod.containers.image.repository resource=%ka.target.name)\n  priority: WARNING\n  source: k8s_audit\n  tags: [k8s]\n```", "```\n21:47:15.063915008: Warning Untrusted image deployed in kube-system namespace (user=admin image=busybox resource=pod-1)\n```", "```\necho \"{\\\"experimental\\\":true}\" >> /etc/docker/daemon.json\n```", "```\n# docker checkpoint\nUsage:\tdocker checkpoint COMMAND\nManage checkpoints\nOptions:\n      --help   Print usage\nCommands:\n  create      Create a checkpoint from a running container\n  ls          List checkpoints for a container\n  rm          Remove a checkpoint\n```", "```\n# docker run -d --name looper --security-opt seccomp:unconfined busybox /bin/sh -c 'i=0; while true; do echo $i; i=$(expr $i + 1); sleep 1; done'\n91d68fafec8fcf11e7699539dec0b037220b1fcc856fb7050c58ab90ae8cbd13\n```", "```\n# sleep 5\n# docker logs looper\n0\n1\n2\n3\n4\n5\n```", "```\n# docker checkpoint create --checkpoint-dir=/tmp looper checkpoint\ncheckpoint\n```", "```\n# docker create --name looper-clone --security-opt seccomp:unconfined busybox /bin/sh -c 'i=0; while true; do echo $i; i=$(expr $i + 1); sleep 1; done'\n49b9ade200e7da6bbb07057da02570347ad6fefbfc1499652ed286b874b59f2b\n```", "```\n# docker start --checkpoint-dir=/tmp --checkpoint=checkpoint looper-clone\n# sleep 5\n# docker logs looper-clone\n6\n7\n8\n9\n10\n```", "```\n08:22:19.484698397: Warning Anomalous file read activity in Nginx pod (user=<NA> process=nginx file=/etc/passwd container_id=439e2e739868 image=kaizheh/insecure-nginx) k8s.ns=insecure-nginx k8s.pod=insecure-nginx-7c99fdf44b-gffp4 container=439e2e739868 k8s.ns=insecure-nginx k8s.pod=insecure-nginx-7c99fdf44b-gffp4 container=439e2e739868\n```", "```\n$ kubectl plugin list\nThe following compatible plugins are available:\n/Users/kaizhehuang/.krew/bin/kubectl-advise_psp\n/Users/kaizhehuang/.krew/bin/kubectl-capture\n/Users/kaizhehuang/.krew/bin/kubectl-ctx\n/Users/kaizhehuang/.krew/bin/kubectl-krew\n/Users/kaizhehuang/.krew/bin/kubectl-ns\n/Users/kaizhehuang/.krew/bin/kubectl-sniff\n```", "```\n$ kubectl capture insecure-nginx-7c99fdf44b-4fl5s -ns insecure-nginx\nSysdig is starting to capture system calls:\nNode: ip-172-20-42-49.ec2.internal\nPod: insecure-nginx-7c99fdf44b-4fl5s\nDuration: 120 seconds\nParameters for Sysdig: -S -M 120 -pk -z -w /capture-insecure-nginx-7c99fdf44b-4fl5s-1587337260.scap.gz\nThe capture has been downloaded to your hard disk at:\n/Users/kaizhehuang/demo/chapter11/sysdig/capture-insecure-nginx-7c99fdf44b-4fl5s-1587337260.scap.gz\n```", "```\n$ docker run -d -v /Users/kaizhehuang/demo/chapter11/sysdig:/captures -p3000:3000 sysdig/sysdig-inspect:latest\n17533f98a947668814ac6189908ff003475b10f340d8f3239cd3627fa9747769\n```", "```\n$ kubectl get pods -o wide\nNAME          READY   STATUS    RESTARTS   AGE   IP               NODE                           NOMINATED NODE   READINESS GATES\nanchore-cli   1/1     Running   1          77m   100.123.226.66   ip-172-20-42-49.ec2.internal   <none>           <none>\n$ kubectl get pods -n insecure-nginx -o wide\nNAME                              READY   STATUS    RESTARTS   AGE   IP               NODE                           NOMINATED NODE   READINESS GATES\ninsecure-nginx-7c99fdf44b-4fl5s   1/1     Running   0          78m   100.123.226.65   ip-172-20-42-49.ec2.internal   <none>           <none>\n```"]